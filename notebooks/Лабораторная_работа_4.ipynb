{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "13d68de6",
      "metadata": {
        "id": "13d68de6"
      },
      "source": [
        "# Лабораторная работа 4. Полносвязные нейронные сети (многослойный персептрон). Решение задач регрессии и классификации"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9f92923",
      "metadata": {
        "id": "e9f92923"
      },
      "source": [
        "## Искусственные нейроны"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d1a07e2",
      "metadata": {
        "id": "8d1a07e2"
      },
      "source": [
        "Искусственными нейронными сетями (чаще - просто нейронными сетями) называются модели машинного обучения, в основе функционирования которых лежат <b>принципы работы биологических нейронов</b> в человеческом мозге. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa8517f9",
      "metadata": {
        "id": "fa8517f9"
      },
      "source": [
        "Идея, лежащая в основе нейронных сетей, очень простая: каждый биологический нейрон имеет несколько входов (дендритов), на основе информации с которых формируется выходной сигнал, который с помощью выхода (аксона) передается далее к органам человеческого (и не только) организма. В 1943 году У. Маккалок и У. Питтс предложили идею искусственного нейрона."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ea8fb4c",
      "metadata": {
        "id": "7ea8fb4c"
      },
      "source": [
        "![](https://upload.wikimedia.org/wikipedia/ru/thumb/b/ba/Single_layer_perceptron.png/270px-Single_layer_perceptron.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38f99850",
      "metadata": {
        "id": "38f99850"
      },
      "source": [
        "Искусственный нейрон также имеет дендриты и аксон. Математически, здесь на вход нейрона подается некоторый вектор из чисел $x$. При этом каждый дендрит имеет свой вес $w$. Значение нейрона $h$ вычисляется как $h=wx^T$, если в векторной форме. А если в скалярной, то речь идет о простом перемножении компонент входного вектора на соответствующие веса связей и последующее суммирование."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c1e50bf",
      "metadata": {
        "id": "7c1e50bf"
      },
      "source": [
        "Заметим, что такой нейрон полностью эквивалентен линейному регрессору, а это значит, что он может находить в данных исключительно линейные зависимости. Чтобы такого не было придумали передавать аксону не $h$, а $f(h)$, где $f$ - нелинейная функция, называемая <b>функцией активации</b>."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f41ff97",
      "metadata": {
        "id": "7f41ff97"
      },
      "source": [
        "Функции активации способны управлять множеством значений нейрона. Ниже приведены некоторые функции активации."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf033d03",
      "metadata": {
        "id": "bf033d03"
      },
      "source": [
        "![](https://programforyou.ru/images/useful/cnn/part0/activations.png?v=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d67a4f37",
      "metadata": {
        "id": "d67a4f37"
      },
      "source": [
        "## Полносвязные нейронные сети. Получение предсказаний"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52a2cce9",
      "metadata": {
        "id": "52a2cce9"
      },
      "source": [
        "Со временем идея искусственных нейронов была обобщена. Появились модели, в которых уже присутствовало несколько взаимосвязанных между собой нейронов. Исторически первым прикладным обобщением сетей из искусственных нейронов является <b>многослойный персептрон</b>. Его концепция была предложена Ф. Розенблатом в 1958 году. Однако персептрон Розенблата имел всего три слоя. Мы же будем рассматривать обобщенную модель."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d046b4bb",
      "metadata": {
        "id": "d046b4bb"
      },
      "source": [
        "![](https://neerc.ifmo.ru/wiki/images/thumb/6/63/Multi-layer-neural-net-scheme.png/500px-Multi-layer-neural-net-scheme.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ea7d5d8",
      "metadata": {
        "id": "6ea7d5d8"
      },
      "source": [
        "Представленая выше нейронная сеть (многослойный персептрон) называется <b>полносвязной</b>. Это означает, что каждый нейрон текущего слоя связан с каждым нейроном предыдущего слоя. Если скрытых нейронов больше чем один, то такая сеть называется <b>глубокой</b>. Обучение глубоких нейронных сетей называется глубоким обучением."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4485ea9e",
      "metadata": {
        "id": "4485ea9e"
      },
      "source": [
        "В сети выделяют входной слой (нейроны, на которых просто размещается вектор входных значений), скрытые слои (у каждого слоя своя функция активации, которую используют все нейроны) и выходной слой (функция активации выходного слоя отображает значения суммы в требуемое множество значений). Вы, наверное, догадались, что в случае регрессии функция активации выходного слоя, как правило, не ограничивает значения нейронов (то есть может вообще не применяться), может отображать значения нейрона в положительное число (например, relu). В случае классификации в большинстве случаев используются функции активации sigmoid и softmax. Как именно они применяются вы увидите на практике ниже."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad3c0722",
      "metadata": {
        "id": "ad3c0722"
      },
      "source": [
        "Получение предсказаний с помощью нейронной сети - это <b>процесс последовательного выполнения матричного умножения с последующим поэлементным применением функции активации к получившемуся вектору<b>. Не верите? давайте это увидим."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5dc34f6",
      "metadata": {
        "id": "d5dc34f6"
      },
      "source": [
        "Каждому слою сети (кроме входного) соответствует матрица обучаемых параметров. Пусть мы рассматриваем первых скрытый слой, обозначим количество его нейронов за $m$. Обозначим количество нейронов предыдущего слоя (входного) за $n$. Тогда матрица весов слоя $W$ будет иметь размерность $m{\\times}n$. Элемент $w_{ij}$ - вес связи $i$ нейрона текущего слоя с $j$ нейроном предыдущего."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "442c1622",
      "metadata": {
        "id": "442c1622"
      },
      "source": [
        "Также каждому слою соответствует собственный вектор $b$ - это значение сдвига. Количество элементов вектора b соответствует количеству нейронов текущего слоя. Значения нейронов текущего слоя $h$ вычисляется как $h=Wx+b$. Выходное значение нейронов вычисляется как $f(h)$, где $f$ - функция активации текущего слоя."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b63a2d7a",
      "metadata": {
        "id": "b63a2d7a"
      },
      "source": [
        "Как вы видите, получить предсказания очень просто. Изначально значения W и b каждого слоя инициализируются случайным образом. Вы понимаете, что для получения адекватных предсказаний нам необходимо выполнить обучение, то есть <b>найти значения W и b для каждого слоя сети, которые позволят минимизировать функцию ошибки</b>."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c7395af",
      "metadata": {
        "id": "4c7395af"
      },
      "source": [
        "## Обучение полносвязных нейронных сетей. Алгоритм обратного распространения ошибки"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "431697ea",
      "metadata": {
        "id": "431697ea"
      },
      "source": [
        "Обучение нейронной сети производится с использованием подходов, в основе которых лежит градиентный спуск. В самом простом случае - это обычный, уже знакомый нам, метод наискорейшего спуска. Но вот задача - все эти методы требуют расчета градиента функции ошибки. А как нам посчитать градиент функции ошибки при использовании нейронной сети? Оказывается, что в этом случае мы не можем просто взять и посчитать сразу весь градиент. Вместо этого, мы можем вычислить его по отдельным частям. Алгоритм вычисления градиента, используемый при обучении нейронных сетей, получил название <b>метод обратного распространения ошибки (backpropagation)</b>. Понимание его работы - это основа вашего понимания работы нейронных сетей."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "376a01ba",
      "metadata": {
        "id": "376a01ba"
      },
      "source": [
        "Суть метода обратного распространения ошибки заключается в том, что мы после получения конечных предсказаний начинаем идти назад (от последнего слоя к первому) и последовательно вычислять части градиента. Как вы, наверное, догадались, обучаемыми параметрами у нас являются $W$ и $b$ для каждого слоя. Мы двигаемся начиная с последнего слоя и последовательно вычисляем эти градиенты."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a241e8a",
      "metadata": {
        "id": "7a241e8a"
      },
      "source": [
        "Для того, чтобы нам удобно было все это понять, давайте каждый слой разобьем еще на два слоя. Для простоты сделаем так, что вся сеть имеет только входной слой и выходной (выходной разбит на два отдельных слоя)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb4a7d99",
      "metadata": {
        "id": "eb4a7d99"
      },
      "source": [
        "![](https://i.vgy.me/S1IeLk.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8e36a3e",
      "metadata": {
        "id": "a8e36a3e"
      },
      "source": [
        "Мы видим, что любую нейронную сеть таким образом можно разбить на большее количество слоев, если каждый слой с функцией активации разбить на два слоя. Представить, что на первом выполняется суммирование произведений (умножение матрицы на вектор и добавление сдвига), а на втором - поэлементное применение функции активации. Продолжая подобные рассуждения, мы придем к тому, что любая полносвязная сеть может быть представлена как набор последовательных компонентов, каждый из которых можно рассматривать как функцию."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11839a14",
      "metadata": {
        "id": "11839a14"
      },
      "source": [
        "![](https://i.vgy.me/7vWpIw.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05c3a7c6",
      "metadata": {
        "id": "05c3a7c6"
      },
      "source": [
        "Каждый такой компонент берет входные данные и преобразует их в выходные (в случае полносвязной нейронной сети компонент либо выполняет линейное преобразование, либо применяет функцию активации). Входные данные текущего блока являются выходными данными предыдущего. Но посмотрите, а что представляют собой тогда выходные данные последнего компонента с математической точки зрения? Это ни что иное, как результат применения <b>сложной функции</b> к входным данным. В данном случае, $y_3=f_3(f_2(f_1(x_1)))$. А теперь давайте вспомним, что каждый эти компоненты содержат обучаемые параметры $W$ и $b$. В данном случае у нас есть $W_1$ и $b_1$, а также $W_3$ и $b_3$ (второй компонент не содержит обучающих параметров, поскольку отвечает за просто поэлементное применение функции активации)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6be6d5ee",
      "metadata": {
        "id": "6be6d5ee"
      },
      "source": [
        "Но мы с вами ранее сказали о том, что градиент вычисляется частично и по каждому множеству обучаемых параметров, так? Да, все именно так. Мат. анализ предоставляет нам замечательный инструмент для вычисления производных сложной функции - <b>цепное правило (chain rule)</b>."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7594ccb",
      "metadata": {
        "id": "f7594ccb"
      },
      "source": [
        "Суть цепного правила вы помните со школы: если $y=y(g(x))$, то ${\\frac{dy}{dx}}={\\frac{dy}{dg}}{\\frac{dg}{dx}}$. То же самое работает и в нашем случае. Каждый компонент использует значения частных производных функции потерь по своему выходу для непосредственного вычисления частных производных функции потерь по $W$ и $b$, а также передает предыдущему компоненту вычисленные значения производной функии потерь по своему входу. Далее компонент с использованием оптимизатора делает шаг градиентного спуска (обновляются значения весов $W$ и $b$). <b>Обращаю внимание: обновление весов выполняется ПОСЛЕ вычисления частных производных по весам</b>."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82dea9a2",
      "metadata": {
        "id": "82dea9a2"
      },
      "source": [
        "![sejsej](https://i.vgy.me/m5KKFF.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98fd14a4",
      "metadata": {
        "id": "98fd14a4"
      },
      "source": [
        "Итак, пусть у нас задана функция потерь. Для регрессии и бинарной классификации можно использовать модифицированную MSE: $E={\\frac{1}{2}}(y-\\hat{y})^2$. Мы хотим ее минимизировать. Ранее мы буквой $L$ обозначали функцию потерь, а при работе с нейронными сетями устоялось обозначение $E$."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca869d1e",
      "metadata": {
        "id": "ca869d1e"
      },
      "source": [
        "Осталось разобраться, по каким формулам вычисляются части градиента в каждом компоненте. Мы знаем, что в каждом компоненте вычисляется $\\frac{\\partial{E}}{\\partial{x}}$. В некоторых компонентах вычисляются $\\frac{\\partial{E}}{\\partial{W}}$ и $\\frac{\\partial{E}}{\\partial{b}}$."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "733f597a",
      "metadata": {
        "id": "733f597a"
      },
      "source": [
        "Запишем формулы:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dad6e1a1",
      "metadata": {
        "id": "dad6e1a1"
      },
      "source": [
        "$\\frac{\\partial{E}}{\\partial{W}}$ = $\\frac{\\partial{E}}{\\partial{y}}x^T$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "abe2984a",
      "metadata": {
        "id": "abe2984a"
      },
      "source": [
        "$\\frac{\\partial{E}}{\\partial{b}}$ = $\\frac{\\partial{E}}{\\partial{y}}$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc66a9d5",
      "metadata": {
        "id": "dc66a9d5"
      },
      "source": [
        "Частные производные функции потерь по входу вычисляются по разному, в зависимости от назначения компонента. Если это компонент, реализующий линейное преобразование ($Wx+b$), то $\\frac{\\partial{E}}{\\partial{x}} = W^T\\frac{\\partial{E}}{\\partial{y}} $. Если это компонент, применяющий функцию активации $f$ (sigmoid, tanh, relu), то $\\frac{\\partial{E}}{\\partial{x}} = \\frac{\\partial{E}}{\\partial{y}}\\odot f'(x) $. $\\odot$ - это поэлементное произведение векторов (произведение Адамара). "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "122831c5",
      "metadata": {
        "id": "122831c5"
      },
      "source": [
        "Можно увидеть, что все функции активации слоев обязаны быть дифференцируемыми. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0382aa47",
      "metadata": {
        "id": "0382aa47"
      },
      "source": [
        "При решении задач классификации (в общем случае, когда количество классов больше двух), как правило, применяется функция потерь перекрестная энтропия (при бинарной классификации применяется ее частный случай - бинарная перекрестная кросэнтропия). Выглядит она следующим образом:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0701bb5a",
      "metadata": {
        "id": "0701bb5a"
      },
      "source": [
        "Общий случай: $E = -\\sum_{k}^{s}{{y_k}ln{\\hat{y_k}}}$. Здесь s - количество классов. При использовании такой функции потерь, предполагается, что целевой признак размечен (например, для случая двух классов) как [1, 0]. Это оначает, что объект относится к 0 классу. Предположим, модель предсказала ответ [0,36, 0,64]. Она ошиблась. Можно посчитать значение перекрестной энтропии и обновить веса."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8ea437c",
      "metadata": {
        "id": "d8ea437c"
      },
      "source": [
        "Как вы видите, использование перекрестной энтропии требует, чтобы сумма значений нейронов была единица и все числа были положительными. Для получения такого результата на произвольном слое с нейронами используется функция softmax. Ее можно назвать функцией активации, однако при использовании softmax $\\frac{\\partial{E}}{\\partial{x}}$ считается по другому. $\\frac{\\partial{E}}{\\partial{x}} = ((1-y^T)y)\\frac{\\partial{E}}{\\partial{y}} $. Подчеркну, что 1 здесь обозначена единичная матрица."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "647ebb36",
      "metadata": {
        "id": "647ebb36"
      },
      "source": [
        "Вот и все. Теперь вы можете реализовать собственную полносвязную нейронную сеть. Для облегчения задачи представьте ее в виде компонентов, как это описано выше. Чтобы начать вычисление градиента необходимо начать двигаться от последнего компонента к первому, при этом предварительно посчитать частную производную функции потерь по выходу последнего компонента."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "adb42973",
      "metadata": {
        "id": "adb42973"
      },
      "source": [
        "## Использование фреймворка TensorFlow и API Keras для построеония нейронных сетей"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b08b38f0",
      "metadata": {
        "id": "b08b38f0"
      },
      "source": [
        "Мы разобрались, как работают полносвязные нейронные сети. Давайте теперь решим задачи регрессии и классификации с помощью фреймворка TensorFlow. Начнем с загрузки предварительно обработанных данных."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5340d31a",
      "metadata": {
        "id": "5340d31a"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '../data/regression/apartment_data_preprocessed.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m data_regression \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39m../data/regression/apartment_data_preprocessed.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      3\u001b[0m data_classification \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39m../data/classification/bank_churners_preprocessed.csv\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\malya\\Desktop\\маш обуч\\venv\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\malya\\Desktop\\маш обуч\\venv\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\malya\\Desktop\\маш обуч\\venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
            "File \u001b[1;32mc:\\Users\\malya\\Desktop\\маш обуч\\venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
            "File \u001b[1;32mc:\\Users\\malya\\Desktop\\маш обуч\\venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
            "File \u001b[1;32mc:\\Users\\malya\\Desktop\\маш обуч\\venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1736\u001b[0m     f,\n\u001b[0;32m   1737\u001b[0m     mode,\n\u001b[0;32m   1738\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1739\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1740\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1741\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1742\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1743\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1744\u001b[0m )\n\u001b[0;32m   1745\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
            "File \u001b[1;32mc:\\Users\\malya\\Desktop\\маш обуч\\venv\\lib\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    857\u001b[0m             handle,\n\u001b[0;32m    858\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    859\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    860\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    861\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    862\u001b[0m         )\n\u001b[0;32m    863\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/regression/apartment_data_preprocessed.csv'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "data_regression = pd.read_csv(\"../data/regression/apartment_data_preprocessed.csv\")\n",
        "data_classification = pd.read_csv(\"../data/classification/bank_churners_preprocessed.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0d04b7d",
      "metadata": {
        "id": "a0d04b7d"
      },
      "outputs": [],
      "source": [
        "data_regression.drop(columns = [\"Unnamed: 0\"], inplace=True)\n",
        "data_classification.drop(columns = [\"Unnamed: 0\"], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef6bc6d4",
      "metadata": {
        "id": "ef6bc6d4",
        "outputId": "61070045-2298-4c89-e866-2bf53ba5b41b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SalePrice</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>MonthSold</th>\n",
              "      <th>Size(sqf)</th>\n",
              "      <th>Floor</th>\n",
              "      <th>N_Parkinglot(Ground)</th>\n",
              "      <th>N_Parkinglot(Basement)</th>\n",
              "      <th>TimeToBusStop</th>\n",
              "      <th>TimeToSubway</th>\n",
              "      <th>...</th>\n",
              "      <th>c_management_in_trust</th>\n",
              "      <th>c_self_management</th>\n",
              "      <th>c_Bangoge</th>\n",
              "      <th>c_Banwoldang</th>\n",
              "      <th>c_Chil-sung-market</th>\n",
              "      <th>c_Daegu</th>\n",
              "      <th>c_Kyungbuk_uni_hospital</th>\n",
              "      <th>c_Myung-duk</th>\n",
              "      <th>c_Sin-nam</th>\n",
              "      <th>c_no_subway_nearby</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>141592</td>\n",
              "      <td>2006</td>\n",
              "      <td>2007</td>\n",
              "      <td>8</td>\n",
              "      <td>814</td>\n",
              "      <td>3</td>\n",
              "      <td>111.0</td>\n",
              "      <td>184.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>51327</td>\n",
              "      <td>1985</td>\n",
              "      <td>2007</td>\n",
              "      <td>8</td>\n",
              "      <td>587</td>\n",
              "      <td>8</td>\n",
              "      <td>80.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>48672</td>\n",
              "      <td>1985</td>\n",
              "      <td>2007</td>\n",
              "      <td>8</td>\n",
              "      <td>587</td>\n",
              "      <td>6</td>\n",
              "      <td>80.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>380530</td>\n",
              "      <td>2006</td>\n",
              "      <td>2007</td>\n",
              "      <td>8</td>\n",
              "      <td>2056</td>\n",
              "      <td>8</td>\n",
              "      <td>249.0</td>\n",
              "      <td>536.0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>221238</td>\n",
              "      <td>1993</td>\n",
              "      <td>2007</td>\n",
              "      <td>8</td>\n",
              "      <td>1761</td>\n",
              "      <td>3</td>\n",
              "      <td>523.0</td>\n",
              "      <td>536.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 41 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   SalePrice  YearBuilt  YrSold  MonthSold  Size(sqf)  Floor  \\\n",
              "0     141592       2006    2007          8        814      3   \n",
              "1      51327       1985    2007          8        587      8   \n",
              "2      48672       1985    2007          8        587      6   \n",
              "3     380530       2006    2007          8       2056      8   \n",
              "4     221238       1993    2007          8       1761      3   \n",
              "\n",
              "   N_Parkinglot(Ground)  N_Parkinglot(Basement)  TimeToBusStop  TimeToSubway  \\\n",
              "0                 111.0                   184.0              1             2   \n",
              "1                  80.0                    76.0              2             3   \n",
              "2                  80.0                    76.0              2             3   \n",
              "3                 249.0                   536.0              2             4   \n",
              "4                 523.0                   536.0              2             1   \n",
              "\n",
              "   ...  c_management_in_trust  c_self_management  c_Bangoge  c_Banwoldang  \\\n",
              "0  ...                      1                  0          0             0   \n",
              "1  ...                      0                  1          0             0   \n",
              "2  ...                      0                  1          0             0   \n",
              "3  ...                      1                  0          0             0   \n",
              "4  ...                      1                  0          0             0   \n",
              "\n",
              "   c_Chil-sung-market  c_Daegu  c_Kyungbuk_uni_hospital  c_Myung-duk  \\\n",
              "0                   0        0                        1            0   \n",
              "1                   0        1                        0            0   \n",
              "2                   0        1                        0            0   \n",
              "3                   0        0                        0            0   \n",
              "4                   0        0                        0            1   \n",
              "\n",
              "   c_Sin-nam  c_no_subway_nearby  \n",
              "0          0                   0  \n",
              "1          0                   0  \n",
              "2          0                   0  \n",
              "3          1                   0  \n",
              "4          0                   0  \n",
              "\n",
              "[5 rows x 41 columns]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_regression.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9df0807a",
      "metadata": {
        "id": "9df0807a",
        "outputId": "6e1a6123-a978-4278-fd47-6834d9096dfb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Attrition_Flag</th>\n",
              "      <th>Customer_Age</th>\n",
              "      <th>Dependent_count</th>\n",
              "      <th>Education_Level</th>\n",
              "      <th>Income_Category</th>\n",
              "      <th>Card_Category</th>\n",
              "      <th>Months_on_book</th>\n",
              "      <th>Total_Relationship_Count</th>\n",
              "      <th>Months_Inactive_12_mon</th>\n",
              "      <th>Contacts_Count_12_mon</th>\n",
              "      <th>...</th>\n",
              "      <th>Total_Trans_Amt</th>\n",
              "      <th>Total_Trans_Ct</th>\n",
              "      <th>Total_Ct_Chng_Q4_Q1</th>\n",
              "      <th>Avg_Utilization_Ratio</th>\n",
              "      <th>c_F</th>\n",
              "      <th>c_M</th>\n",
              "      <th>c_Divorced</th>\n",
              "      <th>c_Married</th>\n",
              "      <th>c_Single</th>\n",
              "      <th>c_Unknown</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>45</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>1144</td>\n",
              "      <td>42</td>\n",
              "      <td>1.625</td>\n",
              "      <td>0.061</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>49</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>44</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>1291</td>\n",
              "      <td>33</td>\n",
              "      <td>3.714</td>\n",
              "      <td>0.105</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>51</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>36</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1887</td>\n",
              "      <td>20</td>\n",
              "      <td>2.333</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>34</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1171</td>\n",
              "      <td>20</td>\n",
              "      <td>2.333</td>\n",
              "      <td>0.760</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>816</td>\n",
              "      <td>28</td>\n",
              "      <td>2.500</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 24 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Attrition_Flag  Customer_Age  Dependent_count  Education_Level  \\\n",
              "0               0            45                3                2   \n",
              "1               0            49                5                5   \n",
              "2               0            51                3                5   \n",
              "3               0            40                4                2   \n",
              "4               0            40                3                1   \n",
              "\n",
              "   Income_Category  Card_Category  Months_on_book  Total_Relationship_Count  \\\n",
              "0                3              0              39                         5   \n",
              "1                1              0              44                         6   \n",
              "2                4              0              36                         4   \n",
              "3                1              0              34                         3   \n",
              "4                3              0              21                         5   \n",
              "\n",
              "   Months_Inactive_12_mon  Contacts_Count_12_mon  ...  Total_Trans_Amt  \\\n",
              "0                       1                      3  ...             1144   \n",
              "1                       1                      2  ...             1291   \n",
              "2                       1                      0  ...             1887   \n",
              "3                       4                      1  ...             1171   \n",
              "4                       1                      0  ...              816   \n",
              "\n",
              "   Total_Trans_Ct  Total_Ct_Chng_Q4_Q1  Avg_Utilization_Ratio  c_F  c_M  \\\n",
              "0              42                1.625                  0.061    0    1   \n",
              "1              33                3.714                  0.105    1    0   \n",
              "2              20                2.333                  0.000    0    1   \n",
              "3              20                2.333                  0.760    1    0   \n",
              "4              28                2.500                  0.000    0    1   \n",
              "\n",
              "   c_Divorced  c_Married  c_Single  c_Unknown  \n",
              "0           0          1         0          0  \n",
              "1           0          0         1          0  \n",
              "2           0          1         0          0  \n",
              "3           0          0         0          1  \n",
              "4           0          1         0          0  \n",
              "\n",
              "[5 rows x 24 columns]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_classification.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc58fb63",
      "metadata": {
        "id": "dc58fb63"
      },
      "outputs": [],
      "source": [
        "y_regression = data_regression[\"SalePrice\"]\n",
        "X_regression = data_regression.drop(columns = ['SalePrice'])\n",
        "y_classification = data_classification['Attrition_Flag']\n",
        "X_classification = data_classification.drop(columns = ['Attrition_Flag'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5cf5839",
      "metadata": {
        "id": "f5cf5839"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_regression_train, X_regression_test, y_regression_train, y_regression_test = train_test_split(X_regression,\n",
        "                                                                                                y_regression,\n",
        "                                                                                                test_size=0.2)\n",
        "X_classification_train, X_classification_test, y_classification_train, y_classification_test = train_test_split(X_classification,\n",
        "                                                                                                                y_classification,\n",
        "                                                                                                                stratify=y_classification,\n",
        "                                                                                                                test_size=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b84f4fc",
      "metadata": {
        "id": "9b84f4fc"
      },
      "source": [
        "Импортируем метрики"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fda21ed2",
      "metadata": {
        "id": "fda21ed2"
      },
      "outputs": [],
      "source": [
        "# для оценки качества решения задачи регрессии\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "# для оценки качества решения задачи классификации\n",
        "from sklearn.metrics import confusion_matrix, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "078d1a1c",
      "metadata": {
        "id": "078d1a1c"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f49610a3",
      "metadata": {
        "id": "f49610a3"
      },
      "source": [
        "### Регрессия"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e563d4d",
      "metadata": {
        "id": "0e563d4d"
      },
      "source": [
        "Создаем полносвязную нейронную сеть для решения задачи регрессии"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3c73d33",
      "metadata": {
        "id": "b3c73d33"
      },
      "outputs": [],
      "source": [
        "# создаем модель, как набор последовательных слоев\n",
        "model_regression = tf.keras.Sequential(\n",
        "    [\n",
        "        # Dense - полносвязный слой (каждый нейрон следующего слоя связан со всеми нейронами предыдущего)\n",
        "        tf.keras.layers.Dense(64, activation=\"relu\", input_shape=(40,)),\n",
        "        # на втором скрытом слое будет 32 нейрона\n",
        "        tf.keras.layers.Dense(32, activation=\"linear\"),\n",
        "        # Dropout позволяет внести фактор случайности - при обучении часть нейронов будет отключаться\n",
        "        # каждый нейрон, в данном случае, будет отключаться с вероятностью 0.1\n",
        "        tf.keras.layers.Dropout(0.1),\n",
        "        tf.keras.layers.Dense(16, activation=\"relu\"),\n",
        "        tf.keras.layers.Dropout(0.1),\n",
        "        # на выходе один нейрон, функция активации не применяется\n",
        "        tf.keras.layers.Dense(1, activation=\"linear\"),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af49e8d0",
      "metadata": {
        "id": "af49e8d0",
        "outputId": "eaee9795-f3d3-4e99-d4f3-f218f0440c11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_10 (Dense)            (None, 64)                2624      \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 16)                0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,249\n",
            "Trainable params: 5,249\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# посмотрим, какая сеть у нас получилась\n",
        "model_regression.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f04c118e",
      "metadata": {
        "id": "f04c118e"
      },
      "source": [
        "Видим количество обучаемых параметров каждого слоя и общее количество обучаемых параметров. Перед использованием модель необходимо скомпилировать, при этом указывается оптимизатор, скорость обучения (можно представлять как величину шага в методе градиентного спуска), функция потерь и метрики, которые мы хотим (при желании) вычислять в будущем методом evaluate()."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11ebc13f",
      "metadata": {
        "id": "11ebc13f"
      },
      "outputs": [],
      "source": [
        "# компилируем\n",
        "model_regression.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.005), loss=\"mse\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d03d027",
      "metadata": {
        "id": "5d03d027",
        "outputId": "66fc9b4f-897f-4f1d-b43d-0699ba361f00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "148/148 [==============================] - 1s 1ms/step - loss: 18677094400.0000\n",
            "Epoch 2/50\n",
            "148/148 [==============================] - 0s 1ms/step - loss: 5956613120.0000\n",
            "Epoch 3/50\n",
            "148/148 [==============================] - 0s 1ms/step - loss: 5302459392.0000\n",
            "Epoch 4/50\n",
            "148/148 [==============================] - 0s 1ms/step - loss: 5173764608.0000\n",
            "Epoch 5/50\n",
            "148/148 [==============================] - 0s 1ms/step - loss: 5024999936.0000\n",
            "Epoch 6/50\n",
            "148/148 [==============================] - 0s 1ms/step - loss: 4719655936.0000\n",
            "Epoch 7/50\n",
            "148/148 [==============================] - 0s 1ms/step - loss: 4645587456.0000\n",
            "Epoch 8/50\n",
            "148/148 [==============================] - 0s 1ms/step - loss: 4634443264.0000\n",
            "Epoch 9/50\n",
            "148/148 [==============================] - 0s 1ms/step - loss: 4532004864.0000\n",
            "Epoch 10/50\n",
            "148/148 [==============================] - 0s 1ms/step - loss: 4173457920.0000\n",
            "Epoch 11/50\n",
            "148/148 [==============================] - 0s 1ms/step - loss: 4276416000.0000\n",
            "Epoch 12/50\n",
            "148/148 [==============================] - 0s 1ms/step - loss: 4374330368.0000\n",
            "Epoch 13/50\n",
            "148/148 [==============================] - 0s 1ms/step - loss: 4385856512.0000\n",
            "Epoch 14/50\n",
            "148/148 [==============================] - 0s 1ms/step - loss: 4252396800.0000\n",
            "Epoch 15/50\n",
            "148/148 [==============================] - 0s 1ms/step - loss: 4199605504.0000\n",
            "Epoch 16/50\n",
            "148/148 [==============================] - 0s 1ms/step - loss: 4403289600.0000\n",
            "Epoch 17/50\n",
            "148/148 [==============================] - 0s 1ms/step - loss: 4192039424.0000\n",
            "Epoch 18/50\n",
            "148/148 [==============================] - 0s 1ms/step - loss: 4135811584.0000\n",
            "Epoch 19/50\n",
            "148/148 [==============================] - 0s 1ms/step - loss: 4035171840.0000\n",
            "Epoch 20/50\n",
            "148/148 [==============================] - 0s 1ms/step - loss: 3964751872.0000\n",
            "Epoch 21/50\n",
            "148/148 [==============================] - 0s 1ms/step - loss: 3939002112.0000\n",
            "Epoch 22/50\n",
            "148/148 [==============================] - 0s 1ms/step - loss: 3839074048.0000\n",
            "Epoch 23/50\n",
            "148/148 [==============================] - 0s 1ms/step - loss: 3839807744.0000\n",
            "Epoch 24/50\n",
            "148/148 [==============================] - 0s 1ms/step - loss: 3713281280.0000\n",
            "Epoch 25/50\n",
            "148/148 [==============================] - 0s 1ms/step - loss: 3728565760.0000\n",
            "Epoch 26/50\n",
            "148/148 [==============================] - 0s 1ms/step - loss: 3852269824.0000\n",
            "Epoch 27/50\n",
            "148/148 [==============================] - 0s 1ms/step - loss: 3693128704.0000\n",
            "Epoch 28/50\n",
            "148/148 [==============================] - 0s 1ms/step - loss: 3828483584.0000\n",
            "Epoch 29/50\n",
            "148/148 [==============================] - 0s 1ms/step - loss: 3818676992.0000\n",
            "Epoch 30/50\n",
            "148/148 [==============================] - 0s 1ms/step - loss: 3677117184.0000\n",
            "Epoch 31/50\n",
            "148/148 [==============================] - 0s 1ms/step - loss: 3871500032.0000\n",
            "Epoch 32/50\n",
            "148/148 [==============================] - 0s 1ms/step - loss: 3598656256.0000\n",
            "Epoch 33/50\n",
            "148/148 [==============================] - 0s 1ms/step - loss: 3614639872.0000\n",
            "Epoch 34/50\n",
            "148/148 [==============================] - 0s 1ms/step - loss: 3749658368.0000\n",
            "Epoch 35/50\n",
            "148/148 [==============================] - 0s 1ms/step - loss: 3680359168.0000\n",
            "Epoch 36/50\n",
            "148/148 [==============================] - 0s 1ms/step - loss: 3564896000.0000\n",
            "Epoch 37/50\n",
            "148/148 [==============================] - 0s 1ms/step - loss: 3581931520.0000\n",
            "Epoch 38/50\n",
            "148/148 [==============================] - 0s 1ms/step - loss: 3631480064.0000\n",
            "Epoch 39/50\n",
            "148/148 [==============================] - 0s 1ms/step - loss: 3530358272.0000\n",
            "Epoch 40/50\n",
            "148/148 [==============================] - 0s 1ms/step - loss: 3542114816.0000\n",
            "Epoch 41/50\n",
            "148/148 [==============================] - 0s 1ms/step - loss: 3609455616.0000\n",
            "Epoch 42/50\n",
            "148/148 [==============================] - 0s 1ms/step - loss: 3496535296.0000\n",
            "Epoch 43/50\n",
            "148/148 [==============================] - 0s 1ms/step - loss: 3556663296.0000\n",
            "Epoch 44/50\n",
            "148/148 [==============================] - 0s 1ms/step - loss: 3478364672.0000\n",
            "Epoch 45/50\n",
            "148/148 [==============================] - 0s 1ms/step - loss: 3352423680.0000\n",
            "Epoch 46/50\n",
            "148/148 [==============================] - 0s 1ms/step - loss: 3440696832.0000\n",
            "Epoch 47/50\n",
            "148/148 [==============================] - 0s 1ms/step - loss: 3313053952.0000\n",
            "Epoch 48/50\n",
            "148/148 [==============================] - 0s 1ms/step - loss: 3312765184.0000\n",
            "Epoch 49/50\n",
            "148/148 [==============================] - 0s 1ms/step - loss: 3432930816.0000\n",
            "Epoch 50/50\n",
            "148/148 [==============================] - 0s 1ms/step - loss: 3333359104.0000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x2666b0d42e0>"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# обучаем, 10 эпох означает 10 проходов по обучающей выборке\n",
        "model_regression.fit(X_regression_train, y_regression_train, epochs=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2fe0b9d4",
      "metadata": {
        "id": "2fe0b9d4",
        "outputId": "5e2c5afc-20ba-44c0-b3a4-c7417f1d97fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "37/37 [==============================] - 0s 889us/step\n",
            "41091.38192125212\n",
            "37/37 [==============================] - 0s 917us/step\n",
            "2485492505.8873043\n"
          ]
        }
      ],
      "source": [
        "# оцениваем качество с помощью метрик\n",
        "print(mean_absolute_error(y_regression_test, model_regression.predict(X_regression_test)))\n",
        "print(mean_squared_error(y_regression_test, model_regression.predict(X_regression_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5399f5ba",
      "metadata": {
        "id": "5399f5ba"
      },
      "source": [
        "Мы получили наглядную демонстрацию важного факта - в некоторых задачах применение нейронных сетей менее целесообразно, чем использование более простых моделей. Но иногда они дают лучшие результаты. Важную роль еще играет подбор архитектуры и параметров."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4838f599",
      "metadata": {
        "id": "4838f599"
      },
      "source": [
        "### Бинарная классификация"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b5c0f56",
      "metadata": {
        "id": "9b5c0f56"
      },
      "source": [
        "Нейронная сеть для решения задачи классификации будет очень похожа на ту сеть для регрессии, однако у нее по другому будет организован выходной слой. У нас есть 2 стратегии наполнения выходного слоя нейронами:\n",
        "\n",
        "- при решении задачи бинарной классификации мы можем расположить на выходном слое один нейрон с функцией активации sigmoid (значения от 0 и 1), после чего округлять полученные значения; значение нейрона покажет уверенность сети в предсказании; также мы можем расположить 2 нейрона на выходном слое и применить функцию softmax. Тогда сумма значений нейронов выходного слоя будет 1, а предсказание мы сможем получить определив нейрон с наибольшим значением;\n",
        "- в случае многоклассовой классификации, как правило, на выходном слое располагаются k нейронов (по количеству классов), функция активации - softmax; нейрон с наибольшим значением определяет предсказанный класс."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cfdc09fe",
      "metadata": {
        "id": "cfdc09fe"
      },
      "source": [
        "У нас задача бинарной классификации, попробуем обе стратегии."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a66cf4a4",
      "metadata": {
        "id": "a66cf4a4",
        "outputId": "b4c9aa05-6b9f-44e8-8086-03a87f6aa200"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x2666b6d8b50>"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_classification_1 = tf.keras.Sequential(\n",
        "    [\n",
        "        tf.keras.layers.Dense(64, activation=\"relu\", input_shape=(23,)),\n",
        "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
        "        tf.keras.layers.Dropout(0.05),\n",
        "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
        "        tf.keras.layers.Dense(32, activation=\"relu\"),\n",
        "        tf.keras.layers.Dense(16, activation=\"relu\"),\n",
        "        # сначала используем 1 нейрон и sigmoid\n",
        "        tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
        "    ]\n",
        ")\n",
        "# в качестве функции активации используется бинарная  кроссэнтропия\n",
        "model_classification_1.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss=\"mse\")\n",
        "# verbose=None - не будет логов\n",
        "model_classification_1.fit(X_classification_train, y_classification_train, epochs=25, verbose=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46e63257",
      "metadata": {
        "id": "46e63257"
      },
      "source": [
        "Посмотрим, как выглядят предсказания сети."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18172a49",
      "metadata": {
        "id": "18172a49",
        "outputId": "5788d18f-ecc8-44f1-950a-cf5d4445dfdd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.]], dtype=float32)"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_classification_1.predict(X_classification_test, verbose=None)[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ef5c89e",
      "metadata": {
        "id": "8ef5c89e"
      },
      "source": [
        "Это числа от 0 до 1, поскольку мы использовали sigmoid. Для того, чтобы получить финальное предсказания классов, необходимо округлить все полученные значения."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "161a4c98",
      "metadata": {
        "id": "161a4c98",
        "outputId": "3fcfcaa3-650b-431c-d32b-d5626fa9ee0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      1.00      0.91      1701\n",
            "           1       0.00      0.00      0.00       325\n",
            "\n",
            "    accuracy                           0.84      2026\n",
            "   macro avg       0.42      0.50      0.46      2026\n",
            "weighted avg       0.70      0.84      0.77      2026\n",
            "\n",
            "[[1701    0]\n",
            " [ 325    0]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "D:\\Programs\\Python\\ml-labs\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "D:\\Programs\\Python\\ml-labs\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "D:\\Programs\\Python\\ml-labs\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "y_pred = np.around(model_classification_1.predict(X_classification_test, verbose=None))\n",
        "print(classification_report(y_classification_test, y_pred))\n",
        "print(confusion_matrix(y_classification_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "048b27da",
      "metadata": {
        "id": "048b27da"
      },
      "source": [
        "Обратите внимание, что дисбаланс классов может привести к неудовлетворительным результатам обучения модели. Необходимо сбалансировать обучающую выборку."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43bc4e63",
      "metadata": {
        "id": "43bc4e63"
      },
      "source": [
        "Но, даже без выполнения балансировки, можно взвесить функцию потерь. Можем указать веса (параметр class_weight), которые будут использоваться при оптимизации функции ошибки. В качестве весов классов можно задать величины, обратные количеству элементов класса."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df16179e",
      "metadata": {
        "id": "df16179e"
      },
      "outputs": [],
      "source": [
        "w0 = 1 / y_classification_train[y_classification_train==0].shape[0]\n",
        "w1 = 1 / y_classification_train[y_classification_train==1].shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1efce734",
      "metadata": {
        "id": "1efce734",
        "outputId": "afe7e5f2-f0c2-45a3-f63b-7c61208df0c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.78      0.85      1701\n",
            "           1       0.38      0.71      0.50       325\n",
            "\n",
            "    accuracy                           0.77      2026\n",
            "   macro avg       0.66      0.75      0.67      2026\n",
            "weighted avg       0.85      0.77      0.79      2026\n",
            "\n",
            "[[1329  372]\n",
            " [  94  231]]\n"
          ]
        }
      ],
      "source": [
        "model_classification_1 = tf.keras.Sequential(\n",
        "    [\n",
        "        tf.keras.layers.Dense(64, activation=\"relu\", input_shape=(23,)),\n",
        "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
        "        tf.keras.layers.Dropout(0.05),\n",
        "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
        "        tf.keras.layers.Dense(32, activation=\"relu\"),\n",
        "        tf.keras.layers.Dense(16, activation=\"relu\"),\n",
        "        # используем 1 нейрон и sigmoid\n",
        "        tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
        "    ]\n",
        ")\n",
        "model_classification_1.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.005), loss=\"binary_crossentropy\")\n",
        "model_classification_1.fit(X_classification_train, y_classification_train, epochs=25, verbose=None,\n",
        "                           class_weight={0: w0, 1: w1})\n",
        "y_pred = np.around(model_classification_1.predict(X_classification_test, verbose=None))\n",
        "print(classification_report(y_classification_test, y_pred))\n",
        "print(confusion_matrix(y_classification_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "370e3660",
      "metadata": {
        "id": "370e3660"
      },
      "source": [
        "Видим улучшения. Можем поиграть с архитектурой и параметрами и добиться еще более качественных результатов. Но напоследок давайте попробуем разместить 2 нейрона на выходном слое и использовать softmax в качестве функции активации."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd17e1c4",
      "metadata": {
        "id": "cd17e1c4",
        "outputId": "56b71377-8862-48d7-d8fb-4829c6ca224c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x26672245a00>"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_classification_2 = tf.keras.Sequential(\n",
        "    [\n",
        "        tf.keras.layers.Dense(64, activation=\"relu\", input_shape=(23,)),\n",
        "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
        "        tf.keras.layers.Dropout(0.05),\n",
        "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
        "        tf.keras.layers.Dense(32, activation=\"relu\"),\n",
        "        tf.keras.layers.Dense(16, activation=\"relu\"),\n",
        "        # сначала используем 2 нейрона и softmax\n",
        "        tf.keras.layers.Dense(2, activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "# в качестве функции активации используется категориальная кроссэнтропия\n",
        "# используем разряженный (sparse) вариант, поскольку значения целевого признака не закодированы One-Hot кодированием\n",
        "model_classification_2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.005), loss=\"sparse_categorical_crossentropy\")\n",
        "model_classification_2.fit(X_classification_train, y_classification_train, epochs=25, verbose=None,\n",
        "                           class_weight={0: w0, 1: w1})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34b44a42",
      "metadata": {
        "id": "34b44a42",
        "outputId": "d34e5d71-0e72-4ab9-ca6c-1af9d6826d73"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.48673633, 0.51326376],\n",
              "       [0.76047015, 0.23952979],\n",
              "       [0.90106165, 0.09893838],\n",
              "       [0.19694562, 0.8030544 ],\n",
              "       [0.19694562, 0.8030544 ]], dtype=float32)"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_classification_2.predict(X_classification_test, verbose=None)[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2f88855",
      "metadata": {
        "id": "c2f88855"
      },
      "source": [
        "Каждое предсказание - это два числа (потому что два нейрона). Сумма значений равна 1. Каждое значение можно интерпретировать как вероятность отнесения объекта к соответствующему классу (0 или 1). Воспользуемся функцией argmax для того, чтобы получить итоговые предсказания."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2143a1ef",
      "metadata": {
        "id": "2143a1ef"
      },
      "outputs": [],
      "source": [
        "# получим индексы максимального значения для каждого элемента (вложенный массив) с помощью numpy\n",
        "y_pred = [np.argmax(pred) for pred in model_classification_2.predict(X_classification_test, verbose=None)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87091ba5",
      "metadata": {
        "id": "87091ba5",
        "outputId": "4ed37b0f-dc35-4c5a-ab0b-51bee6776817"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.78      0.85      1701\n",
            "           1       0.39      0.73      0.50       325\n",
            "\n",
            "    accuracy                           0.77      2026\n",
            "   macro avg       0.66      0.75      0.68      2026\n",
            "weighted avg       0.85      0.77      0.80      2026\n",
            "\n",
            "[[1326  375]\n",
            " [  89  236]]\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_classification_test, y_pred))\n",
        "print(confusion_matrix(y_classification_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2469c34e",
      "metadata": {
        "id": "2469c34e"
      },
      "source": [
        "Когда мы закончили обучение моделей, мы можем сохранить их на диск, чтобы в будущем либо продолжить обучение (если оно занимает много времени) или использовать для получения предсказаний."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a0ea2e8",
      "metadata": {
        "id": "5a0ea2e8",
        "outputId": "67fdc99e-ce2c-4a6d-b174-2e324a94270c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ../models/RegressionModel\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ../models/RegressionModel\\assets\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ../models/ClassificationModel1\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ../models/ClassificationModel1\\assets\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ../models/ClassificationModel2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ../models/ClassificationModel2\\assets\n"
          ]
        }
      ],
      "source": [
        "model_regression.save('../models/RegressionModel')\n",
        "model_classification_1.save('../models/ClassificationModel1')\n",
        "model_classification_2.save('../models/ClassificationModel2')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29fc0974",
      "metadata": {
        "id": "29fc0974"
      },
      "source": [
        "Модели сохранены в виде папки. Теперь, когда они нам потребуются, можем очень просто их загрузить. Загрузим, например, модель для регрессии."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cefa072",
      "metadata": {
        "id": "2cefa072",
        "outputId": "2696f2a6-5c3c-47ea-a885-e7a5f4877500"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_10 (Dense)            (None, 64)                2624      \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 16)                0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,249\n",
            "Trainable params: 5,249\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_regression_restored = tf.keras.models.load_model('../models/RegressionModel')\n",
        "model_regression_restored.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58c837c5",
      "metadata": {
        "id": "58c837c5",
        "outputId": "2f11651c-6436-4423-f520-322df13da4e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "41091.38192125212\n",
            "2485492505.8873043\n"
          ]
        }
      ],
      "source": [
        "# используем модель\n",
        "print(mean_absolute_error(y_regression_test, model_regression_restored.predict(X_regression_test, verbose=None)))\n",
        "print(mean_squared_error(y_regression_test, model_regression_restored.predict(X_regression_test, verbose=None)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gW-NhwXEChTS",
      "metadata": {
        "id": "gW-NhwXEChTS"
      },
      "source": [
        "# Задание"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-IPcUj1UCeIz",
      "metadata": {
        "id": "-IPcUj1UCeIz"
      },
      "source": [
        "<b>Традиционное предупреждение для всех лабораторных работ:</b> перед обучением моделей необходимо выполнить предварительную обработку данных, которая <b>обязательно</b> включает в себя:\n",
        "- заполнение пропущенных значений (рекомедуется логика заполнения пропусков на основе типа данных, которая использовалась в РГР по Практикуму);\n",
        "- преобразование категориальных признаков в числовые (используйте one-hot кодирование или map; используйте знания с Практикума)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jcfIwITzCgTb",
      "metadata": {
        "id": "jcfIwITzCgTb"
      },
      "source": [
        "Предобработка может включать в себя другие действия, но выполнение описанных выше действий обязательно."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "H8y4nWluCkgr",
      "metadata": {
        "id": "H8y4nWluCkgr"
      },
      "source": [
        "Сделайте это один раз и сохраните в отдельный csv файл, а потом его используйте."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "T24SZSN1CmBL",
      "metadata": {
        "id": "T24SZSN1CmBL"
      },
      "source": [
        "<b>Выполните следующие задания:</b>\n",
        "- решите задачи регрессии и классификации на ваших данных используя полносвязные нейронные сети; соберите их используя API Keras фреймворка TensorFlow; оцените качество полученных моделей с помощью метрик; \n",
        "- реализуйте многослойный персептрон, с помощью которого можно решать задачи регрессии и классификации; предусмотрите возможность использовать такие функции активации, как sigmoid, tanh и relu; также предусмотрите возможность указать, сколько слоев нужно, сколько на каждом из них нейронов и какую функцию активации должен иметь слой; реализуйте обучение персептрона методом обратного распространения ошибки; самостоятельно найдите производные функций sigmoid, tanh и relu; реализуйте классический градиентный спуск с возможностью указания шага.\n",
        "\n",
        "<b>Дополнительные задания:</b>\n",
        "- самостоятельно изучите отличия работы оптимизаторов Adam и RMSProp от классического градиентного спуска; реализуйте градиентный спуск с использованием указанных оптимизаторов; предусмотрите возможность использования реализованных вами оптимизаторов в вашем персептроне."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "85014ceb",
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error,r2_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "id": "c4cd1767",
      "metadata": {},
      "outputs": [],
      "source": [
        "data = pd.read_csv('../data/classification/airlines_task.csv')\n",
        "\n",
        "data['Airline'] = data['Airline'].fillna(data['Airline'].mode()[0])\n",
        "data['AirportTo'] = data['AirportTo'].fillna(data['AirportTo'].mode()[0])\n",
        "data['DayOfWeek'] = data['DayOfWeek'].fillna(data['DayOfWeek'].mean())\n",
        "data['Length'] = data['Length'].fillna(data['Length'].mode()[0])\n",
        "data = data.drop('id',axis=1)\n",
        "data = data.drop('Flight',axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "id": "2a491861",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "        Airline  AirportFrom  AirportTo  DayOfWeek  Time      Length\n",
            "0            16           16         54   4.000000  1195  131.000000\n",
            "1            13           13        207   7.000000   707  145.000000\n",
            "2            12           12        194   5.000000   499   42.000000\n",
            "3            15           15        207   2.000000   810   70.000000\n",
            "4             2            2        214   5.000000   985  143.000000\n",
            "...         ...          ...        ...        ...   ...         ...\n",
            "598233       13           13        239   4.000000  1303  141.496847\n",
            "598234        5            5         16   4.223866   690  122.223866\n",
            "598235       16           16         38   4.194679  1094   74.000000\n",
            "598236       14           14        177   2.967713   566  171.613006\n",
            "598237       12           12         16   4.469747  1019   53.825633\n",
            "\n",
            "[598238 rows x 6 columns]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.utils import resample\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "X = data.drop('Delay', axis=1)\n",
        "y = data['Delay'] \n",
        "\n",
        "bn = LabelEncoder()\n",
        "\n",
        "X['Airline'] = bn.fit_transform(X['Airline'])\n",
        "X['AirportFrom'] =  bn.fit_transform(X['Airline'])\n",
        "X['AirportTo'] = bn.fit_transform(X['AirportTo'])\n",
        "\n",
        "smote = SMOTE(random_state=1000)\n",
        "X, y = smote.fit_resample(X, y)\n",
        "\n",
        "\n",
        "print(X)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "scaler.fit(X[[\"DayOfWeek\",\"Time\",\"Length\"]])\n",
        "X[[\"DayOfWeek\",\"Time\",\"Length\"]]= scaler.transform(X[[\"DayOfWeek\",\"Time\",\"Length\"]])\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "id": "ozjLqw6KCoSK",
      "metadata": {
        "id": "ozjLqw6KCoSK"
      },
      "outputs": [],
      "source": [
        "model_classification_2 = tf.keras.Sequential(\n",
        "    [\n",
        "        tf.keras.layers.Dense(64, activation=\"sigmoid\", input_shape=(6,)),\n",
        "        tf.keras.layers.Dense(128, activation=\"sigmoid\"),\n",
        "        tf.keras.layers.Dense(2, activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model_classification_2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.005), loss=\"sparse_categorical_crossentropy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "id": "a2d78651",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "12526/12526 [==============================] - 26s 2ms/step - loss: 0.6814\n",
            "Epoch 2/5\n",
            "12526/12526 [==============================] - 22s 2ms/step - loss: 0.6801\n",
            "Epoch 3/5\n",
            "12526/12526 [==============================] - 24s 2ms/step - loss: 0.6786\n",
            "Epoch 4/5\n",
            "12526/12526 [==============================] - 24s 2ms/step - loss: 0.6781\n",
            "Epoch 5/5\n",
            "12526/12526 [==============================] - 24s 2ms/step - loss: 0.6747\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x26d00e26970>"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_classification_2.fit(X_train, y_train, epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "id": "e6be03b0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6170/6170 [==============================] - 13s 2ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[0.5141568 , 0.48584318],\n",
              "       [0.49629265, 0.5037074 ],\n",
              "       [0.50188625, 0.49811378],\n",
              "       ...,\n",
              "       [0.51708263, 0.48291737],\n",
              "       [0.522285  , 0.477715  ],\n",
              "       [0.49534965, 0.50465035]], dtype=float32)"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_classification_2.predict(X_test,verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "287011de",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "        Airline  AirportFrom  AirportTo  DayOfWeek      Time    Length\n",
            "58298        12           12         79   0.500000  0.531141  0.085496\n",
            "373952       16           16        135   0.166667  0.766270  0.129771\n",
            "126301       14           14         22   0.333333  0.923023  0.164885\n",
            "562220       13           13        148   0.038720  0.680896  0.490894\n",
            "535044       10           10        120   0.408884  0.822253  0.190840\n",
            "...         ...          ...        ...        ...       ...       ...\n",
            "410285       10           10        183   0.250316  0.801260  0.198473\n",
            "223460       15           15         45   0.166667  0.853744  0.160305\n",
            "38739         7            7         79   0.500000  0.528341  0.236641\n",
            "180445       10           10         54   0.000000  0.538838  0.152672\n",
            "591719       12           12        140   0.550680  0.538838  0.091603\n",
            "\n",
            "[197419 rows x 6 columns]\n"
          ]
        }
      ],
      "source": [
        "print(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "id": "8746b4ca",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6170/6170 [==============================] - 9s 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.67      0.63     98707\n",
            "           1       0.62      0.53      0.57     98712\n",
            "\n",
            "    accuracy                           0.60    197419\n",
            "   macro avg       0.61      0.60      0.60    197419\n",
            "weighted avg       0.61      0.60      0.60    197419\n",
            " [[66503 32204]\n",
            " [45910 52802]]\n"
          ]
        }
      ],
      "source": [
        "y_pred = model_classification_2.predict(X_test,verbose=True)\n",
        "y_pred = np.argmax(y_pred,axis = 1)\n",
        "print(classification_report(y_test, y_pred),confusion_matrix(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "080cf2af",
      "metadata": {},
      "outputs": [],
      "source": [
        "model_classification_2.save('../models/ClassificationModel.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "41487bc6",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Make</th>\n",
              "      <th>Year</th>\n",
              "      <th>Distance</th>\n",
              "      <th>Engine_capacity(cm3)</th>\n",
              "      <th>Transmission_Automatic</th>\n",
              "      <th>Transmission_Manual</th>\n",
              "      <th>Fuel_type_Diesel</th>\n",
              "      <th>Fuel_type_Electric</th>\n",
              "      <th>Fuel_type_Hybrid</th>\n",
              "      <th>Fuel_type_Metan/Propan</th>\n",
              "      <th>Fuel_type_Petrol</th>\n",
              "      <th>Fuel_type_Plug-in Hybrid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2011.0</td>\n",
              "      <td>195000.0</td>\n",
              "      <td>1800.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2014.0</td>\n",
              "      <td>135000.0</td>\n",
              "      <td>1500.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1998.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1400.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>2012.0</td>\n",
              "      <td>110000.0</td>\n",
              "      <td>1500.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>2006.0</td>\n",
              "      <td>200000.0</td>\n",
              "      <td>1600.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41002</th>\n",
              "      <td>19</td>\n",
              "      <td>2015.0</td>\n",
              "      <td>89000.0</td>\n",
              "      <td>1500.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41003</th>\n",
              "      <td>2</td>\n",
              "      <td>2009.0</td>\n",
              "      <td>225.0</td>\n",
              "      <td>1500.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41004</th>\n",
              "      <td>5</td>\n",
              "      <td>2016.0</td>\n",
              "      <td>50000.0</td>\n",
              "      <td>1950.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41005</th>\n",
              "      <td>18</td>\n",
              "      <td>2006.0</td>\n",
              "      <td>370000.0</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41006</th>\n",
              "      <td>2</td>\n",
              "      <td>2006.0</td>\n",
              "      <td>300000.0</td>\n",
              "      <td>1500.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>41007 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Make    Year  Distance  Engine_capacity(cm3)  Transmission_Automatic  \\\n",
              "0         1  2011.0  195000.0                1800.0                       1   \n",
              "1         2  2014.0  135000.0                1500.0                       0   \n",
              "2         3  1998.0       1.0                1400.0                       0   \n",
              "3         2  2012.0  110000.0                1500.0                       0   \n",
              "4         4  2006.0  200000.0                1600.0                       0   \n",
              "...     ...     ...       ...                   ...                     ...   \n",
              "41002    19  2015.0   89000.0                1500.0                       0   \n",
              "41003     2  2009.0     225.0                1500.0                       0   \n",
              "41004     5  2016.0   50000.0                1950.0                       1   \n",
              "41005    18  2006.0  370000.0                2000.0                       0   \n",
              "41006     2  2006.0  300000.0                1500.0                       0   \n",
              "\n",
              "       Transmission_Manual  Fuel_type_Diesel  Fuel_type_Electric  \\\n",
              "0                        0                 0                   0   \n",
              "1                        1                 1                   0   \n",
              "2                        1                 0                   0   \n",
              "3                        1                 1                   0   \n",
              "4                        1                 0                   0   \n",
              "...                    ...               ...                 ...   \n",
              "41002                    1                 1                   0   \n",
              "41003                    1                 1                   0   \n",
              "41004                    0                 1                   0   \n",
              "41005                    1                 1                   0   \n",
              "41006                    1                 1                   0   \n",
              "\n",
              "       Fuel_type_Hybrid  Fuel_type_Metan/Propan  Fuel_type_Petrol  \\\n",
              "0                     1                       0                 0   \n",
              "1                     0                       0                 0   \n",
              "2                     0                       0                 1   \n",
              "3                     0                       0                 0   \n",
              "4                     0                       1                 0   \n",
              "...                 ...                     ...               ...   \n",
              "41002                 0                       0                 0   \n",
              "41003                 0                       0                 0   \n",
              "41004                 0                       0                 0   \n",
              "41005                 0                       0                 0   \n",
              "41006                 0                       0                 0   \n",
              "\n",
              "       Fuel_type_Plug-in Hybrid  \n",
              "0                             0  \n",
              "1                             0  \n",
              "2                             0  \n",
              "3                             0  \n",
              "4                             0  \n",
              "...                         ...  \n",
              "41002                         0  \n",
              "41003                         0  \n",
              "41004                         0  \n",
              "41005                         0  \n",
              "41006                         0  \n",
              "\n",
              "[41007 rows x 12 columns]"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.read_csv('../data/regression/moldova_cars_task.csv')\n",
        "X = data.drop('Price(euro)', axis=1) # предикторы \n",
        "y = data['Price(euro)']\n",
        "X['Model'] = X['Model'].fillna(X['Model'].mode()[0])\n",
        "X['Distance'] = X['Distance'].fillna(X['Distance'].mean())\n",
        "X['Year'] = X['Year'].fillna(X['Year'].mean())\n",
        "X['Transmission'] = X['Transmission'].fillna(X['Transmission'].mode()[0])\n",
        "X = pd.get_dummies(X,columns=['Transmission','Fuel_type'])\n",
        "X = X.drop('Style',axis=1)\n",
        "X = X.drop('Model',axis=1)\n",
        "d = X['Make'].unique()\n",
        "dict = {}\n",
        "u = 1\n",
        "for i in d:\n",
        "    dict.update({i:u})\n",
        "    u +=1\n",
        "X['Make'] = X['Make'].map(dict)\n",
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "152a755b",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "94e63ea9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_80 (Dense)            (None, 32)                416       \n",
            "                                                                 \n",
            " dense_81 (Dense)            (None, 24)                792       \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 24)                0         \n",
            "                                                                 \n",
            " dense_82 (Dense)            (None, 16)                400       \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 16)                0         \n",
            "                                                                 \n",
            " dense_83 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,625\n",
            "Trainable params: 1,625\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_regression = tf.keras.Sequential(\n",
        "    [\n",
        "        tf.keras.layers.Dense(32, activation=\"elu\", input_shape=(12,)),\n",
        "        tf.keras.layers.Dense(24, activation=\"elu\"),\n",
        "        tf.keras.layers.Dropout(0.1),\n",
        "        tf.keras.layers.Dense(16, activation=\"elu\"),\n",
        "        tf.keras.layers.Dropout(0.1),\n",
        "        tf.keras.layers.Dense(1, activation=\"relu\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model_regression.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "id": "190440e8",
      "metadata": {},
      "outputs": [],
      "source": [
        "model_regression.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), loss=\"mse\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "6b8bae5f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "897/897 [==============================] - 2s 2ms/step - loss: 3958380032.0000\n",
            "Epoch 2/10\n",
            "897/897 [==============================] - 1s 2ms/step - loss: 3572832256.0000\n",
            "Epoch 3/10\n",
            "897/897 [==============================] - 2s 2ms/step - loss: 3589548032.0000\n",
            "Epoch 4/10\n",
            "897/897 [==============================] - 1s 2ms/step - loss: 3568968960.0000\n",
            "Epoch 5/10\n",
            "897/897 [==============================] - 1s 2ms/step - loss: 3662295296.0000\n",
            "Epoch 6/10\n",
            "897/897 [==============================] - 2s 2ms/step - loss: 3651961600.0000\n",
            "Epoch 7/10\n",
            "897/897 [==============================] - 1s 2ms/step - loss: 3577473280.0000\n",
            "Epoch 8/10\n",
            "897/897 [==============================] - 1s 2ms/step - loss: 3581821440.0000\n",
            "Epoch 9/10\n",
            "897/897 [==============================] - 1s 2ms/step - loss: 3581657088.0000\n",
            "Epoch 10/10\n",
            "897/897 [==============================] - 1s 2ms/step - loss: 3579884544.0000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x26d4fc31670>"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_regression.fit(X_train, y_train, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "bacbb12a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "385/385 [==============================] - 1s 1ms/step\n",
            "MAE: 5332.979416462829\n",
            "MSE: 107129335.14011402\n",
            "MAPE: 1.0583326162724793\n",
            "R^2: 0.18784801227052594\n"
          ]
        }
      ],
      "source": [
        "y_pred = model_regression.predict(X_test)\n",
        "print(f'MAE: {mean_absolute_error(y_test, y_pred)}')\n",
        "print(f'MSE: {mean_squared_error(y_test, y_pred)}')\n",
        "print(f'MAPE: {(mean_absolute_percentage_error(y_test, y_pred))}')\n",
        "print(f'R^2: {r2_score(y_test, y_pred)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "0832a307",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAE: 9673.883280500691\n",
            "R^2: -0.7094643676772643\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import os\n",
        "import sys\n",
        "\n",
        "sys.path.append(str(Path(os.getcwd()).parent))\n",
        "\n",
        "from src.preseptrone.nn import MLP,sigmoid,Layer,mean_squared_error,categorical_cross_entropy_loss,relu,cross_entropy\n",
        "from src.preseptrone.optimiziters import AdamOptimizer,RMSPropOptimizer,SGD\n",
        "\n",
        "\n",
        "mlp = MLP(num_input = 12,num_hidden=[Layer(neron=6,activation_function= sigmoid),\n",
        "                                     Layer(neron=5,activation_function= sigmoid),\n",
        "                                     Layer(neron=1,activation_function= sigmoid)],\n",
        "                                     lossfunc=mean_squared_error,optimizator = RMSPropOptimizer)\n",
        "mlp.train(np.array(X_train), np.array(y_train), learning_rate=0.01, batch_size=16, num_epochs=10)\n",
        "\n",
        "predictions = mlp.predict(X_test)\n",
        "y_pred = mlp.predict(X_test)\n",
        "\n",
        "\n",
        "print(f'MAE: {mean_absolute_error(y_test, y_pred)}')\n",
        "print(f'R^2: {r2_score(y_test, y_pred)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "3b9644f2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAE: 9673.883280500691\n",
            "R^2: -0.7094643676772643\n"
          ]
        }
      ],
      "source": [
        "\n",
        "mlp = MLP(num_input = 12,num_hidden=[Layer(neron=6,activation_function= sigmoid),\n",
        "                                     Layer(neron=5,activation_function= sigmoid),\n",
        "                                     Layer(neron=1,activation_function= sigmoid)],\n",
        "                                     lossfunc=mean_squared_error,optimizator = AdamOptimizer)\n",
        "mlp.train(np.array(X_train), np.array(y_train), learning_rate=0.01, batch_size=16, num_epochs=10)\n",
        "\n",
        "predictions = mlp.predict(X_test)\n",
        "y_pred = mlp.predict(X_test)\n",
        "\n",
        "\n",
        "print(f'MAE: {mean_absolute_error(y_test, y_pred)}')\n",
        "print(f'R^2: {r2_score(y_test, y_pred)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "15ee684a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAE: 9673.883280500691\n",
            "R^2: -0.7094643676772643\n"
          ]
        }
      ],
      "source": [
        "\n",
        "mlp = MLP(num_input = 12,num_hidden=[Layer(neron=6,activation_function= sigmoid),\n",
        "                                     Layer(neron=5,activation_function= sigmoid),\n",
        "                                     Layer(neron=1,activation_function= sigmoid)],\n",
        "                                     lossfunc=mean_squared_error,optimizator = SGD)\n",
        "mlp.train(np.array(X_train), np.array(y_train), learning_rate=0.01, batch_size=16, num_epochs=10)\n",
        "\n",
        "# predictions = mlp.predict(X_test)\n",
        "y_pred = mlp.predict(X_test)\n",
        "\n",
        "\n",
        "print(f'MAE: {mean_absolute_error(y_test, y_pred)}')\n",
        "print(f'R^2: {r2_score(y_test, y_pred)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "2889bb00",
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "\"None of [Int64Index([16722,  1295,  4964,  3399, 13181,  9678, 23464, 13252, 13789,\\n             5339,\\n            ...\\n            20841, 18078, 16216, 21186, 11679, 25799,  5673,  8964, 26154,\\n             6306],\\n           dtype='int64', length=28704)] are in the [columns]\"",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[82], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m y_train_class \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(y_train)\n\u001b[0;32m      3\u001b[0m mlp \u001b[39m=\u001b[39m MLP(num_input \u001b[39m=\u001b[39m \u001b[39m6\u001b[39m,num_hidden\u001b[39m=\u001b[39m[Layer(neron\u001b[39m=\u001b[39m\u001b[39m6\u001b[39m,activation_function\u001b[39m=\u001b[39m sigmoid),\n\u001b[0;32m      4\u001b[0m                                     Layer(neron\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m,activation_function\u001b[39m=\u001b[39m relu),\n\u001b[0;32m      5\u001b[0m                                     Layer(neron\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,activation_function\u001b[39m=\u001b[39m sigmoid)],\n\u001b[0;32m      6\u001b[0m                                     lossfunc\u001b[39m=\u001b[39m categorical_cross_entropy_loss,optimizator\u001b[39m=\u001b[39mAdamOptimizer)\n\u001b[1;32m----> 7\u001b[0m mlp\u001b[39m.\u001b[39;49mtrain(X_train, y_train, learning_rate\u001b[39m=\u001b[39;49m\u001b[39m0.01\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, num_epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m)\n\u001b[0;32m      9\u001b[0m y_pred \u001b[39m=\u001b[39m mlp\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[0;32m     10\u001b[0m y_pred \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mnan_to_num(y_pred, nan\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, posinf\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, neginf\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\malya\\Desktop\\маш обуч\\src\\preseptrone\\nn.py:108\u001b[0m, in \u001b[0;36mMLP.train\u001b[1;34m(self, X, y, learning_rate, batch_size, num_epochs)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[0;32m    107\u001b[0m     indices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mpermutation(\u001b[39mlen\u001b[39m(X))\n\u001b[1;32m--> 108\u001b[0m     X_shuffle \u001b[39m=\u001b[39m X[indices]\n\u001b[0;32m    109\u001b[0m     y_shuffle \u001b[39m=\u001b[39m y[indices]\n\u001b[0;32m    110\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(X), batch_size):\n",
            "File \u001b[1;32mc:\\Users\\malya\\Desktop\\маш обуч\\venv\\lib\\site-packages\\pandas\\core\\frame.py:3813\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3811\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3812\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m-> 3813\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[0;32m   3815\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
            "File \u001b[1;32mc:\\Users\\malya\\Desktop\\маш обуч\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6070\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6067\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   6068\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6070\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   6072\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[0;32m   6073\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6074\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\malya\\Desktop\\маш обуч\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6130\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6128\u001b[0m     \u001b[39mif\u001b[39;00m use_interval_msg:\n\u001b[0;32m   6129\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m-> 6130\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6132\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[0;32m   6133\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "\u001b[1;31mKeyError\u001b[0m: \"None of [Int64Index([16722,  1295,  4964,  3399, 13181,  9678, 23464, 13252, 13789,\\n             5339,\\n            ...\\n            20841, 18078, 16216, 21186, 11679, 25799,  5673,  8964, 26154,\\n             6306],\\n           dtype='int64', length=28704)] are in the [columns]\""
          ]
        }
      ],
      "source": [
        "y_train_class = np.array(y_train)\n",
        "\n",
        "mlp = MLP(num_input = 6,num_hidden=[Layer(neron=6,activation_function= sigmoid),\n",
        "                                    Layer(neron=5,activation_function= relu),\n",
        "                                    Layer(neron=2,activation_function= sigmoid)],\n",
        "                                    lossfunc= categorical_cross_entropy_loss,optimizator=AdamOptimizer)\n",
        "mlp.train(X_train, y_train, learning_rate=0.01, batch_size=100, num_epochs=50)\n",
        "\n",
        "y_pred = mlp.predict(X_test)\n",
        "y_pred = np.nan_to_num(y_pred, nan=0, posinf=0, neginf=0)\n",
        "print(classification_report(np.argmax(y_pred, axis=1),y_test))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
